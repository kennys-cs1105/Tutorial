# Tutorial for Continual Learning

*Created By KennyS*

---

## 持续学习

持续学习（也称为终身学习、增量学习）是机器学习的一个分支，目标是让模型像人类一样**连续学习多个任务 / 知识**，同时保留已学的旧知识，避免**灾难性遗忘**（Catastrophic Forgetting）—— 即模型在学习新任务后，对旧任务的性能急剧下降。

传统机器学习模型通常在固定数据集上训练，而持续学习关注**动态数据流**下的学习能力，核心挑战是平衡 “新知识学习” 与 “旧知识保留”。常见策略分为三类：

1. 参数正则化：通过约束参数更新，保护对旧任务重要的参数，如EWC
2. 记忆重放：存储旧任务的代表性样本，训练新任务时重放，如Replay Buffer
3. 知识蒸馏：让新模型模仿旧模型的输出，迁移旧知识，如LwF

### 弹性权重巩固 EWC

1. 核心思想

EWC是参数正则化的一种方法，核心逻辑是：

- 识别模型中对旧任务重要的参数（通过Fisher信息矩阵衡量）
- 学习新任务时，对这些重要参数的更新施加惩罚，限制其变化幅度，从而保留旧知识

2. 关键步骤

- **计算Fisher信息矩阵**：在旧任务数据上，计算模型参数的梯度平方并平均，得到Fisher信息矩阵的对角线。Fisher信息越大，说明该参数对旧任务的预测结果影响越大，越需要保护
- **添加正则化惩罚**：训练新任务时，损失函数中加入EWC惩罚项

$$
L_{EWC} = L_{new} + \frac{\lambda}{2} \sum_{i}F_{i}(\theta_{i} - \theta_{i}^{*})^{2}
$$

其中，$F_{i}$是Fisher信息，$\theta_{i}^{*}$是旧任务训练得到的参数值，$\lambda$是惩罚强度

3. 特点

- 无需存储旧任务数据，仅需保存旧任务的参数值和Fisher信息矩阵
- 计算和存储成本低，适用于实时学习场景。任务过多时，Fisher 信息累积可能导致参数更新受限。


### 经验回放缓冲区 Replay Buffer

1. 核心思想

Replay Buffer是记忆重放的一种方法，核心逻辑是：

- 存储旧任务的样本，包括特征和标签，称为范例 Examplars
- 训练新任务时，从缓冲区中随机采样样本，与新任务样本混合训练，从而引入旧任务的知识

2. 关键步骤

- **存储策略**：通常存储在CPU以节省GPU显存，容量有限时可采用 “随机替换” 或 “难例保留” 策略
- **采样策略**：训练时随机采样旧样本，与新样本按比例混合，避免新样本主导训练

3. 特点

- 直观有效，接近人类 “复习旧知识” 的学习模式
- 缺点是需要存储数据，缓冲区容量有限时可能无法覆盖旧任务的全部信息


### LwF（Learning without Forgetting）知识蒸馏损失

1. 核心思想

LwF是知识蒸馏类方法的代表，核心逻辑是：

- 用训练好的旧模型（教师模型）指导新模型（学生模型）学习
- 新模型不仅要拟合新任务的标签，还要模型旧模型对旧任务的输出分布，从而记住旧知识

2. 损失函数

LwF的总损失有两部分组成 $L_{LwF} = L_{new} + L_{distill}$ 

其中，
- $L_{new}$ 是新任务的损失函数，如交叉熵损失
- $L_{distill}$ 是知识蒸馏损失，定义为教师模型输出与学生模型输出的 KL 散度

$$
L_{distill} = \text{KL}(Q(\theta_{old} | x) || P(\theta_{new} | x))
$$

其中，$Q(\theta_{old} | x)$ 是教师模型在旧任务上的输出分布，$P(\theta_{new} | x)$ 是学生模型在新任务上的输出分布。

3. 训练过程

- 先在旧任务上训练教师模型，得到初始参数 $\theta_{old}$
- 用 $\theta_{old}$ 初始化学生模型，开始在新任务上训练
- 每个训练迭代中，计算 $L_{new}$ 和 $L_{distill}$，并更新学生模型参数

4. 特点

- 简单实现，无需复杂的存储和检索机制
- 适用于离线学习场景，也可用于实时学习场景